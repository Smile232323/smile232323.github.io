---
permalink: /
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---
<div class="home-page-content">

<h1 class="main-heading">Hi there <img class="heading-icon" src="images/Hi.gif" width="40" height="40" alt="waving hand"> Welcome to my Homepage!</h1>

I am an undergraduate (2022-2026) at Xidian University, focusing on Computer Vision and Robot Learning.

I work at [MMLab@HKU](https://mmlab.hk/) with [Prof. Xihui Liu](https://xh-liu.github.io/).
Previously I worked at [MVIG@SJTU](https://www.mvig.org/index.html) with [Prof. Lixin Yang](https://lixiny.github.io/) and [Prof. Cewu Lu](https://www.mvig.org/index.html).

Currently I conduct the VLA research at [ByteDance Seed](https://seed.bytedance.com/en/).

News
---------------
- *[Dense Policy](https://selen-suyue.github.io/DspNet) is accepted in ICCV 2025 &#128293;*
- *[MBA](https://selen-suyue.github.io/MBApage) is accepted in IEEE RA-L 2025 &#128293;*
- *Our work AdvDisplay was accepted at AAAI 2025 &#128293;*
- *In charge of [Microsoft Club](https://github.com/MSC-XDU). Feel free to reach out if you'd like to join.*

Experience
--------------
<div class="experience-container">
  <div class="experience-card">
      <img src="images/bytedance.png" alt="Seed logo" class="experience-logo">
      <div class="experience-info">
          <strong>ByteDance Seed</strong><br>
          Oct 2025 - Now<br>
          MLE Intern at <a href="https://seed.bytedance.com/en/"><em>Seed-Robotics</em></a> 
      </div>
  </div>

  <div class="experience-card">
      <img src="images/HKU.png" alt="HKU logo" class="experience-logo">
      <div class="experience-info">
          <strong>The University of Hong Kong</strong><br>
          June 2025 - Now<br>
          Research Intern at <a href="https://mmlab.hk/"><em>MMLab@HKU</em></a> 
      </div>
  </div>

  <div class="experience-card">
      <img src="images/astri.png" alt="astri logo" class="experience-logo">
      <div class="experience-info">
          <strong>Astribot Inc.</strong><br>
          June 2025 - Sep 2025<br>
          MLE Intern advised by <a href="https://scholar.google.com/citations?user=mt5mvZ8AAAAJ&hl=en"><em>Jianan Wang</em></a>
      </div>
  </div>

  <div class="experience-card">
      <img src="images/SJTU.png" alt="SJTU logo" class="experience-logo">
      <div class="experience-info">
          <strong>Shanghai Jiao Tong University</strong><br>
          July 2024 - June 2025<br>
          Research Intern at <a href="https://www.mvig.org/index.html"><em>MVIG</em></a> Lab
      </div>
  </div>

  <div class="experience-card">
      <img src="images/XDU.png" alt="Xi'dian logo" class="experience-logo">
      <div class="experience-info">
          <strong>Xidian University</strong><br>
          Sep 2022 - July 2026<br>
          Rank 4/174, <b>National Scholarship</b><br>
          B.E at <a href="https://sai.xidian.edu.cn"><em>SAI</em></a> & RA at <a href="https://web.xidian.edu.cn/mggong/"><em>OMEGA</em></a> Lab
      </div>
  </div>
</div>

Publications
--------------
<div class="pub-button-container">
  <button class="pub-button active" type="button" data-filter="all" aria-pressed="true">All Publications</button>
  <button class="pub-button" type="button" data-filter="featured" aria-pressed="false">Selected Only</button>
</div>

<div class="publication-card">
  <div class="media-row">
    <video class="pub-media" width="200" height="120" autoplay loop muted playsinline preload="metadata" poster="images/dobot.png">
      <source src="images/clap.mp4" type="video/mp4">
    </video>
    <div>
        <strong>CLAP: Contrastive Latent Action Pretraining for Learning Vision-Language-Action Models from Human Videos</strong><br>
        <i class="author-list">
            <a href="https://lin-shan.com/" target="_blank" rel="noopener noreferrer">Chubin Zhang</a>*,
            <a href="https://scholar.google.com/citations?user=mt5mvZ8AAAAJ&hl=en" target="_blank" rel="noopener noreferrer">Jianan Wang</a>*, 
            Zifeng Gao, 
            <a href="https://selen-suyue.github.io" target="_blank" rel="noopener noreferrer"><strong>Yue Su</strong></a>, 
            Tiranru Dai,
            <a href="https://homepage.zhouc.ai/" target="_blank" rel="noopener noreferrer">Cai Zhou</a>, <br>
            <a href="https://ivg.au.tsinghua.edu.cn/Jiwen_Lu/" target="_blank" rel="noopener noreferrer">Jiwen Lu</a>,
            <a href="https://andytang15.github.io/" target="_blank" rel="noopener noreferrer">Yansong Tang</a>&dagger;
        </i><br>
        Learning Vision-Language-Action Models from Human Videos.
        <br>
        <b><i class="venue-tag">ArXiv Preprint &nbsp;</i></b>
        <a href="https://arxiv.org/abs/2601.04061"><em>[arXiv]</em></a>
        <em>[code coming soon]</em>
        <a href="https://lin-shan.com/CLAP/#"><em>[website]</em></a>
    </div>
  </div>
</div>

<div class="publication-card featured">
  <div class="media-row">
    <video class="pub-media" width="200" height="120" autoplay loop muted playsinline preload="metadata" poster="images/dsp.png">
      <source src="images/dspv2.mp4" type="video/mp4">
    </video>
    <div>
        <strong>DSPv2: Improved Dense Policy for Effective and Generalizable Whole-body Mobile Manipulation</strong><br>
        <i class="author-list">
            <a href="https://selen-suyue.github.io" target="_blank" rel="noopener noreferrer"><strong>Yue Su</strong></a>, 
            <a href="https://lin-shan.com/" target="_blank" rel="noopener noreferrer">Chubin Zhang</a>, 
            <a href="https://ch3cook-fdu.github.io/" target="_blank" rel="noopener noreferrer">Sijin Chen</a>,
            Liufan Tan, <br>
            <a href="https://andytang15.github.io/" target="_blank" rel="noopener noreferrer">Yansong Tang</a>,
            <a href="https://scholar.google.com/citations?user=mt5mvZ8AAAAJ&hl=en" target="_blank" rel="noopener noreferrer">Jianan Wang</a>,
            <a href="https://xh-liu.github.io/" target="_blank" rel="noopener noreferrer">Xihui Liu</a>&dagger;
        </i><br>
        Improved Dense Policy for Whole-body Mobile Manipulation, with effective perception, generalizable manipulation and coherent actions.
        <br>
        <b><i class="venue-tag">ArXiv Preprint &nbsp;</i></b>
        <a href="https://arxiv.org/abs/2509.16063"><em>[arXiv]</em></a>
        <a href="https://github.com/Selen-Suyue/DSPv2"><em>[code]</em></a>
        <a href="https://selen-suyue.github.io/DSPv2Net/"><em>[website]</em></a>
    </div>
  </div>
</div>

<div class="publication-card featured">
 <div class="media-row">
    <video class="pub-media" width="200" height="120" autoplay loop muted playsinline preload="metadata" poster="images/dsp.png">
      <source src="images/flower_dsp.mp4" type="video/mp4">
    </video>
    <div>
        <strong>Dense Policy: Bidirectional Autoregressive Learning of Actions</strong><br>
        <i class="author-list">
            <a href="https://selen-suyue.github.io" target="_blank" rel="noopener noreferrer"><strong>Yue Su</strong></a>*, 
            <a href="https://scholar.google.com/citations?user=WurpqEMAAAAJ&hl=en" target="_blank" rel="noopener noreferrer">Xinyu Zhan</a>*, 
            <a href="https://tonyfang.net/" target="_blank" rel="noopener noreferrer">Hongjie Fang</a>, 
            <a href="https://hanxue.me/" target="_blank" rel="noopener noreferrer">Han Xue</a>, <br>
            <a href="https://fang-haoshu.github.io/" target="_blank" rel="noopener noreferrer">Haoshu Fang</a>, 
            <a href="https://dirtyharrylyl.github.io/" target="_blank" rel="noopener noreferrer">Yong-Lu Li</a>, 
            <a href="http://mvig.org" target="_blank" rel="noopener noreferrer">Cewu Lu</a>, 
            <a href="https://lixiny.github.io" target="_blank" rel="noopener noreferrer">Lixin Yang</a>&dagger;
        </i><br>
        Propose Dense Policy, A bidirectional robotic autoregressive policy, which infers trajectories by gradually expanding actions from sparse keyframes, demonstrated exceeding diffusion policies.<br>
        <b><i class="venue-tag">ICCV 2025 &nbsp;</i></b>
        <a href="https://openaccess.thecvf.com/content/ICCV2025/html/Su_Dense_Policy_Bidirectional_Autoregressive_Learning_of_Actions_ICCV_2025_paper.html"><em>[paper]</em></a>
        <a href="https://arxiv.org/abs/2503.13217"><em>[arXiv]</em></a>
        <a href="https://selen-suyue.github.io/DspNet/"><em>[website]</em></a>
        <a href="https://github.com/Selen-Suyue/DensePolicy"><em>[3D-code]</em></a>
        <a href="https://github.com/Selen-Suyue/DensePolicy2D"><em>[2D-code]</em></a>
    </div>
</div>
</div>

<div class="publication-card featured">
 <div class="media-row">
    <img class="pub-media" src="images/mba_animation.gif" alt="MBA" width="200" height="100" loading="lazy" decoding="async">
    <div>
        <strong>Motion Before Action: Diffusing Object Motion as Manipulation Condition</strong><br>
        <i class="author-list">
            <a href="https://selen-suyue.github.io" target="_blank" rel="noopener noreferrer"><strong>Yue Su</strong></a>*, 
            <a href="https://scholar.google.com/citations?user=WurpqEMAAAAJ&hl=en" target="_blank" rel="noopener noreferrer">Xinyu Zhan</a>*, 
            <a href="https://tonyfang.net/" target="_blank" rel="noopener noreferrer">Hongjie Fang</a>, 
            <a href="https://dirtyharrylyl.github.io/" target="_blank" rel="noopener noreferrer">Yong-Lu Li</a>, 
            <a href="http://mvig.org" target="_blank" rel="noopener noreferrer">Cewu Lu</a>, 
            <a href="https://lixiny.github.io" target="_blank" rel="noopener noreferrer">Lixin Yang</a>&dagger;
        </i><br>
        Propose MBA, a novel plug-and-play module leveraging cascaded diffusion processes to generate actions guided by object motion, enabling seamless integration with manipulation policies.<br>
      <b><i class="venue-tag">RA-L 2025, ICRA 2026 &nbsp;</i></b>
        <a href="https://ieeexplore.ieee.org/abstract/document/11027642"><em>[paper]</em></a>
        <a href="https://arxiv.org/abs/2411.09658"><em>[arxiv]</em></a> 
        <a href="https://selen-suyue.github.io/MBApage"><em>[website]</em></a>
        <a href="https://github.com/Selen-Suyue/MBA"><em>[code]</em></a>
    </div>
</div>
</div>

<div class="publication-card non-featured">
    <img class="pub-media" src="images/GAP.png" alt="RIaa" width="200" height="100" loading="lazy" decoding="async">
    <div>
        <strong>Generative Adversarial Patches for Physical Attacks on Cross-Modal Pedestrian Re-Identification</strong><br>
       <i class="author-list">
    <a href="https://selen-suyue.github.io" target="_blank" rel="noopener noreferrer"><strong>Yue Su</strong></a>, 
    <a href="https://scholar.google.com/citations?user=JkQmO-kAAAAJ&hl=en" target="_blank" rel="noopener noreferrer">Hao Li</a>&dagger;, 
    <a href="https://web.xidian.edu.cn/mggong/" target="_blank" rel="noopener noreferrer">Maoguo Gong</a>&dagger;
    </i><br>
    A generative physical adversarial attack on VI-ReID models perturbs modality-invariant features. <br>
    <b><i class="venue-tag">ArXiv Preprint &nbsp;</i></b>
      <a href="https://arxiv.org/abs/2410.20097"><em>[arxiv]</em></a>
    </div>
</div>

<div class="publication-card non-featured">
    <img class="pub-media" src="images/iraa.png" alt="Raa" width="200" height="100" loading="lazy" decoding="async">
    <div>
        <strong>AdvDisplay: Adversarial Display Assembled by Thermoelectric Cooler for Fooling Thermal Infrared Detectors</strong><br>
      <i class="author-list">
    <a href="https://scholar.google.com/citations?user=JkQmO-kAAAAJ&hl=en" target="_blank" rel="noopener noreferrer">Hao Li</a>&dagger;, 
    <a href="https://scholar.google.com/citations?user=eX7Ra5UAAAAJ&hl=en" target="_blank" rel="noopener noreferrer">Fanggao Wan</a>, 
    <a href="https://selen-suyue.github.io" target="_blank" rel="noopener noreferrer"><strong>Yue Su</strong></a>, 
    <a href="https://ywuchina.github.io/" target="_blank" rel="noopener noreferrer">Yue Wu</a>, 
    <a href="https://scholar.google.com/citations?user=h4PExPwAAAAJ&hl=en" target="_blank" rel="noopener noreferrer">Mingyang Zhang</a>, 
    <a href="https://web.xidian.edu.cn/mggong/" target="_blank" rel="noopener noreferrer">Maoguo Gong</a>&dagger;
    </i><br>
      Historically, infrared adversarial attacks were single-use and tough to deploy. Using TEC, we implemented efficient attacks adaptable to hardware scenarios.
      <br>
      <b><i class="venue-tag">AAAI 2025 &nbsp;</i></b>
      <a href="https://ojs.aaai.org/index.php/AAAI/article/view/34011"><em>[paper]</em></a>
    </div>
</div>


Projects
--------
<div class="project-card">
 <div class="media-row">
    <img class="project-media" src="images/MetaPalace.png" alt="MetaPalace" width="200" height="100" loading="lazy" decoding="async">
    <div>
        <strong>MetaPalace: Let you in a meta world of The Palace Museum</strong><br>
We've done what the Old Palace official website couldn't: offering 3D artifact views with single-view reconstruction and an interactive LLM-powered tour guider using RAG technology. <br>
      <a href="https://metapalace.xj63.fun/"><em>[website]</em></a> 
      <a href="https://github.com/xj63/MetaPalaceSite"><em>[front-end code]</em></a>
      <a href="https://github.com/Selen-Suyue/MetaPalace"><em>[back-end code]</em></a>
    </div>
</div>
</div>


Awards
--------
- Xiaomi Outstanding Scholarship 2025
- National Scholarship 2025
- Outstanding Student, Xidian University, 2025

Talks
--------
- [2025/12] Invited to [Talk on NICE seminar](https://www.bilibili.com/video/BV1utBrBfED4?spm_id_from=333.788.videopod.episodes&p=9) about Imitation Learning
- [2025/12] Invited to [Talk on RL China](https://b23.tv/We6FLQh) about DSPv2
- [2025/10] Invited to [Talk on 3D视觉工坊](https://b23.tv/PvLKNR1) about DSP and DSPv2

</div>
